# DeepSeek and the Jevons Paradox

*Why cheaper AI might mean MORE GPU demand, not less.*

---

## The Panic

January 2025. DeepSeek drops R1. Claims $6M training cost vs. GPT-4's $100M. NVIDIA loses $600 billion in market cap in a single day—the largest one-day loss in US market history.

The narrative: If AI gets 10x cheaper, we need 10x fewer chips. NVIDIA is toast.

But there's a 160-year-old economic principle that says the opposite might be true.

---

## The Paradox

In 1865, English economist William Stanley Jevons noticed something strange about coal. 

James Watt had made steam engines dramatically more efficient. Common sense said this would reduce coal consumption—same output, less fuel.

Instead, coal usage *exploded*. 

Why? Because cheaper energy unlocked new uses. Suddenly, industries that couldn't afford steam power could. The efficiency gains didn't reduce demand—they *expanded the market*.

Jevons called it the "rebound effect." We call it the Jevons Paradox: **When you make a resource cheaper to use, you often end up using more of it, not less.**

---

## The Bridge to AI

DeepSeek's efficiency gains are real. Mixture-of-experts architecture. Better distillation. Optimized inference. Bain estimates inference costs dropped 280x in the two years before DeepSeek even arrived.

But here's what the NVIDIA bears miss:

**1. Latent demand is massive.** Most companies haven't deployed AI at scale because it's too expensive. Cheaper inference doesn't kill demand—it unlocks it. Every enterprise that said "too costly" now says "let's try it."

**2. Usage expands to fill the gap.** When API calls cost $0.01 instead of $1.00, developers don't make the same calls cheaper. They make 100x more calls. Agents that iterate. Reasoning loops. Multi-modal workflows. Cheap unlocks *new architectures*.

**3. The denominator grows faster than the efficiency gains.** Yes, DeepSeek uses 10x fewer FLOPs per inference. But if 50x more inferences happen because it's now affordable, net compute demand goes up 5x.

This is exactly what Bain's analysis suggests: "Ongoing efficiency improvements would lead to cheaper inference, spurring greater AI adoption—a pattern known as Jevons' paradox."

---

## So What?

The market priced DeepSeek as a demand destroyer. History suggests it might be a demand accelerant.

Watch for:
- **API call volumes** at OpenAI, Anthropic, Google—are they rising post-efficiency gains?
- **Enterprise adoption rates**—is cheaper inference finally moving POCs to production?
- **New use cases**—what wasn't possible at $1/query that's now viable at $0.01?

If Jevons was right about coal, he might be right about compute.

The most efficient engine in history didn't reduce fuel consumption. It launched the Industrial Revolution.

---

*What connections are you seeing? Reply or comment.*
