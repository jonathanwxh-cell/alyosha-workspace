{
  "last_check": "2026-02-04T16:00:06.081990",
  "known_releases": {
    "deepseek-ai/DeepSeek-V3": {
      "tag": "v1.0.0",
      "name": "v1.0.0",
      "published": "2025-06-27T08:46:37Z",
      "url": "https://github.com/deepseek-ai/DeepSeek-V3/releases/tag/v1.0.0",
      "body": "This release is created for archival purposes and DOI generation."
    },
    "meta-llama/llama-models": {
      "tag": "v0.2.0",
      "name": "v0.2.0",
      "published": "2025-04-05T19:02:56Z",
      "url": "https://github.com/meta-llama/llama-models/releases/tag/v0.2.0",
      "body": "Llama 4 Support ( https://www.llama.com ) \r\n\r\n"
    },
    "openai/openai-python": {
      "tag": "v2.16.0",
      "name": "v2.16.0",
      "published": "2026-01-27T23:27:23Z",
      "url": "https://github.com/openai/openai-python/releases/tag/v2.16.0",
      "body": "## 2.16.0 (2026-01-27)\n\nFull Changelog: [v2.15.0...v2.16.0](https://github.com/openai/openai-python/compare/v2.15.0...v2.16.0)\n\n### Features\n\n* **api:** api update ([b97f9f2](https://github.com/openai/openai-python/commit/b97f9f26b9c46ca4519130e60a8bf12ad8d52bf3))\n* **api:** api updates ([9debcc0](https://github.com/openai/openai-python/commit/9debcc02370f5b76a6a609ded18fbf8dea87b9cb))\n* **client:** add support for binary request streaming ([49561d8](https://github.com/openai/openai-python/commi"
    }
  }
}