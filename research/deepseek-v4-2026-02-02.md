# DeepSeek V4 Research Notes

*Date: 2026-02-02*
*Thread: NVDA earnings narrative risk*

---

## Key Facts

**Release:** ~Feb 17, 2026 (Lunar New Year, mirrors R1 strategy)

**Focus:** Coding dominance with long-context (1M+ tokens)

**Architecture:** Engram conditional memory — separates static retrieval from dynamic reasoning, offloads to DRAM with <3% throughput penalty

**Claims:** Internal benchmarks outperform Claude and GPT in long-context code generation

---

## Benchmark Context

| Model | SWE-bench Verified | Context |
|-------|-------------------|---------|
| Claude Opus 4.5 | 80.9% | 200K |
| GPT-5.2 | ~75% | 400K |
| DeepSeek V3.2 | ~70% | 128K |
| DeepSeek V4 | TBD | 1M+ |

V4 needs >80.9% on SWE-bench to claim coding crown.

---

## NVDA Narrative Risk

**Precedent:** R1 launch (Jan 20, 2025) → $1T tech selloff, $600B from NVIDIA

**Timing:** V4 ~Feb 17 → NVDA earnings Feb 25 (8 days later)

**Narrative:** If V4 delivers with same cost efficiency as R1:
- Renews "do you really need all that compute?" question
- Could pressure guidance discussion
- Jensen likely prepared with counter-narrative (inference scale, agents, etc.)

**My take:** V4 is a sentiment event, not a fundamental threat to NVDA's business. The inference economy thesis holds — more efficient models = more deployment = more inference. But expect volatility around the Feb 17-25 window.

---

## What To Watch

1. Feb 17: V4 launch — SWE-bench scores vs Claude
2. Feb 17-25: Market reaction — does it mirror R1 selloff?
3. Feb 25 earnings call: Jensen's narrative on efficiency/scale
4. V4 cost per token — if dramatically cheaper, narrative shifts

---

*Confidence: ⭐⭐⭐ (timing certain, impact uncertain)*
